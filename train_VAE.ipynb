{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a36911f",
   "metadata": {},
   "source": [
    "## Implementation of standard VAE and trainning procedure\n",
    "\n",
    "The implementation inspired by: https://github.com/jmtomczak/intro_dgm/blob/main/vaes/vae_example.ipynb and https://github.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/blob/master/7_Unsupervised/7.2-EXE-variational-autoencoder.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a4f960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6092bd35",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "The dataset contain 68x68 images of single cells treated with different compounds. For each of the utilized compounds there is an associated mechanism of action (moa), which describes how the compound it affecting the cell. There are 12 different classes of moa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "132ddce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd.read_csv wiht pyarrow took 775.9014341831207 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "metadata = pd.read_csv('/Users/mikkelrasmussen/mnt/deep_learning_project/data/metadata.csv', engine=\"pyarrow\")\n",
    "print(\"pd.read_csv wiht pyarrow took %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01cfd0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "DMSO_indx = metadata.index[metadata['moa'] == 'DMSO']\n",
    "DMSO_drop_indices = np.random.choice(DMSO_indx, size=260360, replace=False)\n",
    "\n",
    "metadata_subsampled = metadata.drop(DMSO_drop_indices).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5df7b2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moa</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Microtubule stabilizers</td>\n",
       "      <td>89157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aurora kinase inhibitors</td>\n",
       "      <td>16810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DNA damage</td>\n",
       "      <td>16582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DMSO</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Microtubule destabilizers</td>\n",
       "      <td>15178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Epithelial</td>\n",
       "      <td>14955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Eg5 inhibitors</td>\n",
       "      <td>12525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kinase inhibitors</td>\n",
       "      <td>11622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Protein synthesis</td>\n",
       "      <td>9715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actin disruptors</td>\n",
       "      <td>7491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Protein degradation</td>\n",
       "      <td>6589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DNA replication</td>\n",
       "      <td>5976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cholesterol-lowering</td>\n",
       "      <td>5436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          moa  counts\n",
       "10    Microtubule stabilizers   89157\n",
       "1    Aurora kinase inhibitors   16810\n",
       "4                  DNA damage   16582\n",
       "3                        DMSO   16000\n",
       "9   Microtubule destabilizers   15178\n",
       "7                  Epithelial   14955\n",
       "6              Eg5 inhibitors   12525\n",
       "8           Kinase inhibitors   11622\n",
       "12          Protein synthesis    9715\n",
       "0            Actin disruptors    7491\n",
       "11        Protein degradation    6589\n",
       "5             DNA replication    5976\n",
       "2        Cholesterol-lowering    5436"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_subsampled.groupby(\"moa\").size().reset_index(name='counts').sort_values(by=\"counts\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "899fb8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DMSO': 0,\n",
       " 'Microtubule stabilizers': 1,\n",
       " 'Eg5 inhibitors': 2,\n",
       " 'Epithelial': 3,\n",
       " 'Actin disruptors': 4,\n",
       " 'Microtubule destabilizers': 5,\n",
       " 'Aurora kinase inhibitors': 6,\n",
       " 'Protein degradation': 7,\n",
       " 'DNA replication': 8,\n",
       " 'DNA damage': 9,\n",
       " 'Protein synthesis': 10,\n",
       " 'Kinase inhibitors': 11,\n",
       " 'Cholesterol-lowering': 12}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map from class name to class index\n",
    "classes = {index: name for name, index in enumerate(metadata[\"moa\"].unique())}\n",
    "classes_inv = {v: k for k, v in classes.items()}\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7ae2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleCellDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, annotation_file, images_folder, class_map, \n",
    "                 mode='train', transform = None):\n",
    "        self.df = annotation_file\n",
    "        self.images_folder = images_folder\n",
    "        self.transform = transform\n",
    "        self.class2index = class_map\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        filename = self.df.loc[index, \"Single_Cell_Image_Name\"]\n",
    "        label = self.class2index[self.df.loc[index, \"moa\"]]\n",
    "        subfolder = re.search(\"(.*)_\", filename).group(1)\n",
    "        image = np.load(os.path.join(self.images_folder, subfolder, filename))\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image.astype(np.float32))\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d35d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Digits(Dataset):\n",
    "    \"\"\"Scikit-Learn Digits dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, mode='train', transforms=None):\n",
    "        digits = load_digits()\n",
    "        if mode == 'train':\n",
    "            self.data = digits.data[:1000].astype(np.float32)\n",
    "        elif mode == 'val':\n",
    "            self.data = digits.data[1000:1350].astype(np.float32)\n",
    "        else:\n",
    "            self.data = digits.data[1350:].astype(np.float32)\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878b9315",
   "metadata": {},
   "source": [
    "### Code for the standard Variational Autoencoder (VAE)\n",
    "\n",
    "#### Functions for probability distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ff01f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PI = torch.from_numpy(np.asarray(np.pi))\n",
    "EPS = 1.0e-5\n",
    "\n",
    "def log_categorical(x, p, num_classes=12, reduction=None, dim=None):\n",
    "    x_one_hot = F.one_hot(x.long(), num_classes=-1)\n",
    "    log_p = x_one_hot * torch.log(torch.clamp(p, EPS, 1.0 - EPS))\n",
    "    if reduction == 'avg':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "\n",
    "def log_bernoulli(x, p, reduction=None, dim=None):\n",
    "    pp = torch.clamp(p, EPS, 1.0 - EPS)\n",
    "    log_p = x * torch.log(pp) + (1.0 - x) * torch.log(1.0 - pp)\n",
    "    if reduction == 'avg':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "    \n",
    "\n",
    "def log_normal_diag(x, mu, log_var, reduction=None, dim=None):\n",
    "    D = x.shape[1]\n",
    "    log_p = -0.5 * D * torch.log(2.0 * PI) - 0.5 * log_var - 0.5 * torch.exp(-log_var) * (x - mu)**2\n",
    "    if reduction == 'avg':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "\n",
    "def log_standard_normal(x, reduction=None, dim=None):\n",
    "    D = x.shape[1]\n",
    "    log_p = -0.5 * D * torch.log(2.0 * PI) - 0.5 * x**2\n",
    "    if reduction == 'avg':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beb9976",
   "metadata": {},
   "source": [
    "#### Encoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "53e285ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, encoder_net):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # The init of the encoder network\n",
    "        self.encoder = encoder_net\n",
    "    \n",
    "    # The reparameterization trick for Gaussians\n",
    "    @staticmethod\n",
    "    def reparameterization(mu, log_var):\n",
    "        # The formula is the following:\n",
    "        # z = mu + std * epsilon\n",
    "        \n",
    "        # First, we need to get std from log-variance\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        \n",
    "        # Second, we sample epsilon from Normal(0, 1)\n",
    "        eps = torch.randn_like(std)\n",
    "        \n",
    "        # Finally, z is calculated\n",
    "        z = mu + std * eps\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    # This function implements the output of the encoder network \n",
    "    # (i.e., parameters of a Gaussian)\n",
    "    def encode(self, x):\n",
    "        # First, we calculate the output of the encoder network of size 2M.\n",
    "        h_e = self.encoder(x)\n",
    "        \n",
    "        # Second, we must divide the output to the mean and log-variance.\n",
    "        mu_e, log_var_e = torch.chunk(h_e, 2, dim=1)\n",
    "        \n",
    "        return mu_e, log_var_e\n",
    "    \n",
    "    # Sampling procedure.\n",
    "    def sample(self, x=None, mu_e=None, log_var_e=None):\n",
    "        # If we do not provide a mean an a log-variance, we must first calculate it:\n",
    "        if (mu_e is None) and (log_var_e is None):\n",
    "            mu_e, log_var_e = self.encode(x)\n",
    "        \n",
    "        # Or the final sample\n",
    "        else:\n",
    "            # Otherwise, we can simply apply the reparameterization trick!\n",
    "            if (mu_e is None) and (log_var_e is None):\n",
    "                raise ValueError('mu and log-var cannot be None!')\n",
    "        \n",
    "        z = self.reparameterization(mu_e, log_var_e)\n",
    "        return z\n",
    "    \n",
    "    # This function calculates the log-probability that is later used for calculating the ELBO.\n",
    "    def log_prob(self, x=None, mu_e=None, log_var_e=None, z=None):\n",
    "        # If we provide x alone, then we can calculate a corresponding sample.\n",
    "        if x is not None:\n",
    "            mu_e, log_var_e = self.encode(x)\n",
    "            z = self.sample(mu_e=mu_e, log_var_e=log_var_e)\n",
    "        else:\n",
    "        # Otherwise, we should provide mu, log-var and z!\n",
    "            if (mu_e is None) or (log_var_e is None) or (z is None):\n",
    "                raise ValueError('mu, log-var and z cannot be None!')\n",
    "                \n",
    "        return log_normal_diag(z, mu_e, log_var_e)\n",
    "    \n",
    "    # PyTorch forward pass: it is either log-probability (by default) or sampling.\n",
    "    def forward(self, x, type='log_prob'):\n",
    "        assert type in ['encode', 'log_prob'], 'Type could be either encode or log_prob'\n",
    "        if type == 'log_prob':\n",
    "            return self.log_prob(x)\n",
    "        else:\n",
    "            return self.sample(x)            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83876de4",
   "metadata": {},
   "source": [
    "#### Decoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "aa3559a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, decoder_net, distribution='categorical', num_vals=None):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # The decoder network.\n",
    "        self.decoder = decoder_net\n",
    "        # The distribution used for the decoder (it is categorical by default)\n",
    "        self.distribution = distribution\n",
    "        # The number of possible values. This is important for the categorical distribution.\n",
    "        self.num_vals = num_vals\n",
    "    \n",
    "    # This function calculates parameters of the likelihood function p(x|z)\n",
    "    def decode(self, z):\n",
    "        # First, we apply the decoder network.\n",
    "        h_d = self.decoder(z)\n",
    "        \n",
    "        # We will mainly use the categorical distribution.\n",
    "        if self.distribution == 'categorical':\n",
    "            # We save the shapes: batch size\n",
    "            b = h_d.shape[0]\n",
    "            # and the dimensionality of x.\n",
    "            d = h_d.shape[1]//self.num_vals\n",
    "            # Then we reshape to (Batch size, Dimensionality, Number of Values)\n",
    "            h_d = h_d.view(b, d, self.num_vals)\n",
    "            # To get probabilities, we apply softmax\n",
    "            mu_d = torch.softmax(h_d, 2)\n",
    "            return [mu_d]\n",
    "        \n",
    "        # ... however, we also present the Bernoulli distribution.\n",
    "        elif self.distribution == 'bernoulli':\n",
    "            # In the Bernoulli case, we have x_d \\in {0, 1}.\n",
    "            # Therefore, it is enough to output a single probability,\n",
    "            # because p(x_d=1|z) = \\theta and p(x_d=0|z) = 1 - \\theta\n",
    "            mu_d = torch.sigmoid(h_d)\n",
    "            return [mu_d]\n",
    "        else:\n",
    "            raise ValueError('Distribution must be either: categorical or bernoulli')\n",
    "        \n",
    "    # This function implements sampling from the decoder\n",
    "    def sample(self, z):\n",
    "        outs = self.decode(z)\n",
    "        \n",
    "        if self.distribution == 'categorical':\n",
    "            # We take the output of the decoder\n",
    "            mu_d = outs[0]\n",
    "            # and save shapes (we will need that for reshaping).\n",
    "            b = mu_d.shape[0]\n",
    "            m = mu_d.shape[1]\n",
    "            # Here we use reshaping\n",
    "            mu_d = mu_d.view(b, -1, self.num_vals)\n",
    "            p = mu_d.view(-1, self.num_vals)\n",
    "            # Eventually, we sample from the categorical (the built-in PyTorch function)\n",
    "            x_new = torch.multinomial(p, num_samples=1).view(b, m)\n",
    "            return x_new\n",
    "            \n",
    "        elif self.distribution == 'bernoulli':\n",
    "            # In the case of Bernoulli, we do not need any reshaping\n",
    "            mu_d = outs[0]\n",
    "            # and we can use the built-in PyTorch sampler!\n",
    "            x_new = torch.bernoulli(mu_d)\n",
    "            return x_new\n",
    "    \n",
    "        else: \n",
    "            raise ValueError('Distribution must be either: categorical or bernoulli')\n",
    "            \n",
    "    # This function calculates the conditional log-likelihood function.\n",
    "    def log_prob(self, x, z):\n",
    "        outs = self.decode(z)\n",
    "        \n",
    "        if self.distribution == 'categorical':\n",
    "            mu_d = outs[0]\n",
    "            log_p = log_categorical(x, mu_d, num_classes=self.num_vals, \n",
    "                                    reduction='sum', dim=-1).sum(-1)\n",
    "            \n",
    "        elif self.distribution == 'bernoulli':\n",
    "            mu_d = outs[0]\n",
    "            log_p = log_bernoulli(x, mu_d, reduction='sum', dim=-1)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError('Distribution must be either: categorical or bernoulli')\n",
    "        \n",
    "        return log_p\n",
    "    \n",
    "    # The forward pass is either a log-prob or a sample.\n",
    "    def forward(self, z, x=None, type='log_prob'):\n",
    "        assert type in ['decoder', 'log_prob'], 'Type could be either decode or log_prob'\n",
    "        if type == 'log_prob':\n",
    "            return self.log_prob(x, z)\n",
    "        else:\n",
    "            return self.sample(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6bc610",
   "metadata": {},
   "source": [
    "#### Prior class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "825f5aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The current implementation of the prior is very simple, namely, it is a standard Gaussian.\n",
    "# We could have used a built-in PyTorch distribution. However, we did not do that for two reasons:\n",
    "#    (i): It is important to think of the prior as a crucial component in VAEs\n",
    "#    (ii): We can implement a learnable prior (e.g. a flow-based prior, VampPrior, a mixture of distributions)\n",
    "\n",
    "class Prior(nn.Module):\n",
    "    def __init__(self, L):\n",
    "        super(Prior, self).__init__()\n",
    "        self.L = L\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        z = torch.randn((batch_size, self.L))\n",
    "        return z\n",
    "    \n",
    "    def log_prob(self, z):\n",
    "        return log_standard_normal(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd897cd",
   "metadata": {},
   "source": [
    "#### Full VAE class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "0199aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder_net, decoder_net, num_vals=256, L=16, likelihood_type='categorical'):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(encoder_net=encoder_net)\n",
    "        self.decoder = Decoder(distribution=likelihood_type,\n",
    "                              decoder_net=decoder_net, num_vals=num_vals)\n",
    "        self.prior = Prior(L=L)\n",
    "        self.num_vals = num_vals\n",
    "        self.likelihood_type = likelihood_type\n",
    "        \n",
    "    def forward(self, x, reduction='avg'):\n",
    "        # Encoder\n",
    "        mu_e, log_var_e = self.encoder.encode(x)\n",
    "        z = self.encoder.sample(mu_e=mu_e, log_var_e=log_var_e)\n",
    "        \n",
    "        # ELBO        \n",
    "        RE = self.decoder.log_prob(x, z)\n",
    "        KL = (self.prior.log_prob(z) - self.encoder.log_prob(mu_e=mu_e, log_var_e=log_var_e, z=z)).sum(-1)\n",
    "        \n",
    "        if reduction == 'sum':\n",
    "            return -(RE + KL).sum()\n",
    "        elif reduction == 'avg':\n",
    "            return -(RE + KL).mean()\n",
    "        else:\n",
    "            raise ValueError('reduction must be either: sum or avg')\n",
    "    \n",
    "    def sample(self, batch_size=64):\n",
    "        z = self.prior.sample(batch_size=batch_size)\n",
    "        return self.decoder.sample(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f83d756",
   "metadata": {},
   "source": [
    "#### Auxiliary functions for training, evaluation and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "9bf598ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(test_loader, name=None, model_best=None, epoch=None,\n",
    "               device='cpu'):\n",
    "    # EVALUATION\n",
    "    if model_best is None:\n",
    "        # load best performing model\n",
    "        model_best = torch.load(name + '.model')\n",
    "\n",
    "    model_best.eval()\n",
    "    loss = 0.\n",
    "    N = 0.\n",
    "    for indx_batch, (test_batch, test_target) in enumerate(test_loader):\n",
    "        test_batch = test_batch.to(device)\n",
    "        \n",
    "        loss_t = model_best.forward(test_batch, reduction='sum')\n",
    "        loss = loss + loss_t.item()\n",
    "        N = N + test_batch.shape[0]\n",
    "    loss = loss / N\n",
    "\n",
    "    if epoch is None:\n",
    "        print(f'FINAL LOSS: nll={loss}')\n",
    "    else:\n",
    "        print(f'Epoch: {epoch}, val nll={loss}')\n",
    "\n",
    "    return loss\n",
    "\n",
    "def samples_real(name, test_loader):\n",
    "    # REAL-------\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = next(iter(test_loader)).detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], (8, 8))\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name+'_real_images.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "def samples_generated(name, data_loader, extra_name=''):\n",
    "    x = next(iter(data_loader)).detach().numpy()\n",
    "\n",
    "    # GENERATIONS-------\n",
    "    model_best = torch.load(name + '.model')\n",
    "    model_best.eval()\n",
    "\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = model_best.sample(num_x * num_y)\n",
    "    x = x.detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], (8, 8))\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name + '_generated_images' + extra_name + '.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "def plot_curve(name, nll_val):\n",
    "    plt.plot(np.arange(len(nll_val)), nll_val, linewidth='3')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('nll')\n",
    "    plt.savefig(name + '_nll_val_curve.pdf', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "8ca47c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader):\n",
    "    nll_val = []\n",
    "    best_nll = 1000.\n",
    "    patience = 0\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\">> Using device: {device}\")\n",
    "\n",
    "    # move the model to the device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Main loop\n",
    "    for e in range(num_epochs):\n",
    "        # TRAINING\n",
    "        model.train()\n",
    "        for indx_batch, (batch, target) in enumerate(training_loader):\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            if hasattr(model, 'dequantization'):\n",
    "                if model.dequantization:\n",
    "                    batch = batch + torch.rand(batch.shape)\n",
    "                    \n",
    "            loss = model.forward(batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        loss_val = evaluation(val_loader, model_best=model, epoch=e, device=device)\n",
    "        nll_val.append(loss_val)  # save for plotting\n",
    "\n",
    "        if e == 0:\n",
    "            print('saved!')\n",
    "            torch.save(model, name + '.model')\n",
    "            best_nll = loss_val\n",
    "        else:\n",
    "            if loss_val < best_nll:\n",
    "                print('saved!')\n",
    "                torch.save(model, name + '.model')\n",
    "                best_nll = loss_val\n",
    "                patience = 0\n",
    "\n",
    "                samples_generated(name, val_loader, extra_name=\"_epoch_\" + str(e))\n",
    "            else:\n",
    "                patience = patience + 1\n",
    "\n",
    "        if patience > max_patience:\n",
    "            break\n",
    "\n",
    "    nll_val = np.asarray(nll_val)\n",
    "\n",
    "    return nll_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcfa15b",
   "metadata": {},
   "source": [
    "#### Initialize dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "31cab733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1824\n",
      "228\n",
      "228\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "train_data = Digits(mode='train')\n",
    "val_data = Digits(mode='val')\n",
    "test_data = Digits(mode='test')\n",
    "\n",
    "training_loader_digit = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader_digit = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader_digit = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "result_dir = 'results/'\n",
    "if not(os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)\n",
    "name = 'vae'\n",
    "\n",
    "\n",
    "images_folder = \"/Users/mikkelrasmussen/mnt/deep_learning_project/data/singh_cp_pipeline_singlecell_images\"\n",
    "train_transforms = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Lambda(lambda x: torch.flatten(x)),\n",
    "     transforms.Lambda(lambda x: x/x.max())]\n",
    ")\n",
    "train_set = SingleCellDataset(images_folder=images_folder, \n",
    "                              annotation_file=metadata_subsampled, \n",
    "                              transform=train_transforms,\n",
    "                              class_map=classes)\n",
    "\n",
    "#sampler = RandomSampler(train_set, replacement=False, num_samples=100)\n",
    "#train_dataloader = DataLoader(train_set, sampler=sampler, \n",
    "#                              batch_size=batch_size, drop_last=True)\n",
    "\n",
    "# Define the size of the train, validation and test datasets\n",
    "data_prct = 0.01\n",
    "train_prct = 0.8\n",
    "\n",
    "data_amount = int(len(metadata_subsampled) * data_prct)\n",
    "train_size = int(train_prct * data_amount)\n",
    "val_size = (data_amount - train_size) // 2\n",
    "test_size = (data_amount - train_size) // 2\n",
    "\n",
    "indicies = torch.randperm(len(metadata_subsampled))\n",
    "train_indices = indicies[:train_size]\n",
    "val_indicies = indicies[train_size:train_size+val_size]\n",
    "test_indicies = indicies[train_size+val_size:train_size+val_size+test_size]\n",
    "\n",
    "# Checking there are not overlapping incdicies\n",
    "print(sum(np.isin(train_indices.numpy() , [val_indicies.numpy(), test_indicies.numpy()])))\n",
    "print(sum(np.isin(val_indicies.numpy() , [train_indices.numpy(), test_indicies.numpy()])))\n",
    "print(sum(np.isin(test_indicies.numpy() , [train_indices.numpy(), val_indicies.numpy()])))\n",
    "\n",
    "training_set = torch.utils.data.Subset(train_set, train_indices.tolist())\n",
    "val_set = torch.utils.data.Subset(train_set, val_indicies.tolist())\n",
    "testing_set = torch.utils.data.Subset(train_set, test_indicies.tolist())\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testing_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(len(training_loader.dataset))\n",
    "print(len(val_loader.dataset))\n",
    "print(len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfca6b11",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "4f17ac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 64   # input dimension\n",
    "L = 16  # number of latents\n",
    "M = 256  # the number of neurons in scale (s) and translation (t) nets\n",
    "\n",
    "lr = 1e-3 # learning rate\n",
    "num_epochs = 1000 # max. number of epochs\n",
    "max_patience = 20 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfa7e25",
   "metadata": {},
   "source": [
    "#### Initialize VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "25a33d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER:\n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1           [-1, 1, 64, 256]          16,640\n",
      "         LeakyReLU-2           [-1, 1, 64, 256]               0\n",
      "            Linear-3           [-1, 1, 64, 256]          65,792\n",
      "         LeakyReLU-4           [-1, 1, 64, 256]               0\n",
      "            Linear-5            [-1, 1, 64, 32]           8,224\n",
      "================================================================\n",
      "Total params: 90,656\n",
      "Trainable params: 90,656\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 0.52\n",
      "Params size (MB): 0.35\n",
      "Estimated Total Size (MB): 0.88\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "\n",
      "DECODER:\n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1           [-1, 1, 16, 256]           4,352\n",
      "         LeakyReLU-2           [-1, 1, 16, 256]               0\n",
      "            Linear-3           [-1, 1, 16, 256]          65,792\n",
      "         LeakyReLU-4           [-1, 1, 16, 256]               0\n",
      "            Linear-5          [-1, 1, 16, 1088]         279,616\n",
      "================================================================\n",
      "Total params: 349,760\n",
      "Trainable params: 349,760\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.26\n",
      "Params size (MB): 1.33\n",
      "Estimated Total Size (MB): 1.59\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "likelihood_type = 'categorical'\n",
    "\n",
    "if likelihood_type == 'categorical':\n",
    "    num_vals = 17\n",
    "elif likelihood_type == 'bernoulli':\n",
    "    num_vals = 1\n",
    "\n",
    "encoder = nn.Sequential(nn.Linear(D, M), nn.LeakyReLU(),\n",
    "                        nn.Linear(M, M), nn.LeakyReLU(),\n",
    "                        nn.Linear(M, 2 * L))\n",
    "\n",
    "decoder = nn.Sequential(nn.Linear(L, M), nn.LeakyReLU(),\n",
    "                        nn.Linear(M, M), nn.LeakyReLU(),\n",
    "                        nn.Linear(M, num_vals * D))\n",
    "\n",
    "prior = torch.distributions.MultivariateNormal(torch.zeros(L), torch.eye(L))\n",
    "model = VAE(encoder_net=encoder, decoder_net=decoder, num_vals=num_vals, L=L, likelihood_type=likelihood_type)\n",
    "\n",
    "# Print the summary (like in Keras)\n",
    "print(\"ENCODER:\\n\")\n",
    "print(summary(encoder, input_size=(1, D, D)))\n",
    "print(\"\\nDECODER:\\n\")\n",
    "print(summary(decoder, input_size=(1, L, L)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "45e42b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZER\n",
    "optimizer = torch.optim.Adamax([p for p in model.parameters() if p.requires_grad == True], lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c9e3c1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Using device: cpu\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [241]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Training procedure\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m nll_val \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mmax_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_patience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                   \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mtraining_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [236]\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# TRAINING\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m indx_batch, (batch, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(training_loader):\n\u001b[1;32m     17\u001b[0m         batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdequantization\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/utils/data/dataset.py:290\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36mSingleCellDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     15\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass2index[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmoa\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     16\u001b[0m subfolder \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(.*)_\u001b[39m\u001b[38;5;124m\"\u001b[39m, filename)\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimages_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/numpy/lib/npyio.py:397\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    395\u001b[0m _ZIP_SUFFIX \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPK\u001b[39m\u001b[38;5;130;01m\\x05\u001b[39;00m\u001b[38;5;130;01m\\x06\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# empty zip files start with this\u001b[39;00m\n\u001b[1;32m    396\u001b[0m N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX)\n\u001b[0;32m--> 397\u001b[0m magic \u001b[38;5;241m=\u001b[39m \u001b[43mfid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# If the file size is less than N, we need to make sure not\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# to seek past the beginning of the file\u001b[39;00m\n\u001b[1;32m    400\u001b[0m fid\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mmin\u001b[39m(N, \u001b[38;5;28mlen\u001b[39m(magic)), \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# back-up\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training procedure\n",
    "nll_val = training(name=result_dir + name, \n",
    "                   max_patience=max_patience, \n",
    "                   num_epochs=1, \n",
    "                   model=model, \n",
    "                   optimizer=optimizer,\n",
    "                   training_loader=training_loader, \n",
    "                   val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9a6a47e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (10x13872 and 64x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [242]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(result_dir \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_test_loss.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28mstr\u001b[39m(test_loss))\n",
      "Input \u001b[0;32mIn [235]\u001b[0m, in \u001b[0;36mevaluation\u001b[0;34m(test_loader, name, model_best, epoch, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indx_batch, (test_batch, test_target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_loader):\n\u001b[1;32m     12\u001b[0m     test_batch \u001b[38;5;241m=\u001b[39m test_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 14\u001b[0m     loss_t \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_best\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m+\u001b[39m loss_t\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     16\u001b[0m     N \u001b[38;5;241m=\u001b[39m N \u001b[38;5;241m+\u001b[39m test_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "Input \u001b[0;32mIn [234]\u001b[0m, in \u001b[0;36mVAE.forward\u001b[0;34m(self, x, reduction)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Encoder\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     mu_e, log_var_e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39msample(mu_e\u001b[38;5;241m=\u001b[39mmu_e, log_var_e\u001b[38;5;241m=\u001b[39mlog_var_e)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# ELBO        \u001b[39;00m\n",
      "Input \u001b[0;32mIn [231]\u001b[0m, in \u001b[0;36mEncoder.encode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# First, we calculate the output of the encoder network of size 2M.\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     h_e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Second, we must divide the output to the mean and log-variance.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     mu_e, log_var_e \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mchunk(h_e, \u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10x13872 and 64x256)"
     ]
    }
   ],
   "source": [
    "test_loss = evaluation(name=result_dir + name, test_loader=test_loader)\n",
    "f = open(result_dir + name + '_test_loss.txt', \"w\")\n",
    "f.write(str(test_loss))\n",
    "f.close()\n",
    "\n",
    "samples_real(result_dir + name, test_loader)\n",
    "\n",
    "plot_curve(result_dir + name, nll_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4425bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "indx_batch, batch = next(iter(enumerate(training_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83be8694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1., 15.,  ..., 16., 16.,  2.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  2.,  ..., 16.,  8.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  7.,  ..., 14.,  6.,  0.],\n",
       "        [ 0.,  0.,  0.,  ..., 15.,  8.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  6.,  0.,  0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6c914f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86192702",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_new = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db42b44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[  704.,   720.,   688.,  ...,  7584.,  8112.,  8608.],\n",
       "         [  816.,   848.,   784.,  ...,  7328.,  8208., 10288.],\n",
       "         [  544.,   480.,   528.,  ...,  1232.,  1264.,  1312.],\n",
       "         ...,\n",
       "         [  672.,   640.,   624.,  ...,  5616.,  5328.,  4976.],\n",
       "         [ 2048.,  2112.,  2320.,  ...,  2496.,  2496.,  2320.],\n",
       "         [  544.,   592.,   624.,  ...,  8496., 10272., 11872.]]),\n",
       " tensor([ 4,  1,  1,  0,  1, 11,  1,  9,  1,  1,  8,  1,  1,  5, 10,  1,  6,  0,\n",
       "          2, 12,  3,  1, 10,  1,  2,  5, 10,  3,  3,  3,  3,  2, 11,  5,  1,  9,\n",
       "          3,  2,  1,  4, 11,  1,  2,  1,  1, 12,  3,  1,  2,  7, 12,  1,  1,  6,\n",
       "          0,  1,  1,  1, 12,  9,  9,  5,  1,  4])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bb8b69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
